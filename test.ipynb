{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from typing import Any, Callable, List, Optional\n",
    "\n",
    "################### Modefied shufflenet definition ###########################\n",
    "\n",
    "def channel_shuffle(x: Tensor, groups: int) -> Tensor:\n",
    "    batchsize, num_channels, height, width = x.size()\n",
    "    channels_per_group = num_channels // groups\n",
    "\n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups, channels_per_group, height, width)\n",
    "\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, height, width)\n",
    "\n",
    "    return x\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp: int, oup: int, stride: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not (1 <= stride <= 3):\n",
    "            raise ValueError(\"illegal stride value\")\n",
    "        self.stride = stride\n",
    "\n",
    "        branch_features = oup // 2\n",
    "        if (self.stride == 1) and (inp != branch_features << 1):\n",
    "            raise ValueError(\n",
    "                f\"Invalid combination of stride {stride}, inp {inp} and oup {oup} values. If stride == 1 then inp should be equal to oup // 2 << 1.\"\n",
    "            )\n",
    "\n",
    "        if self.stride > 1:\n",
    "            self.branch1 = nn.Sequential(\n",
    "                self.depthwise_conv(inp, inp, kernel_size=3, stride=self.stride, padding=1),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.Conv2d(inp, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(branch_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            self.branch1 = nn.Sequential()\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                inp if (self.stride > 1) else branch_features,\n",
    "                branch_features,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            self.depthwise_conv(branch_features, branch_features, kernel_size=3, stride=self.stride, padding=1),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def depthwise_conv(\n",
    "        i: int, o: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False\n",
    "    ) -> nn.Conv2d:\n",
    "        return nn.Conv2d(i, o, kernel_size, stride, padding, bias=bias, groups=i)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.stride == 1:\n",
    "            x1, x2 = x.chunk(2, dim=1)\n",
    "            out = torch.cat((x1, self.branch2(x2)), dim=1)\n",
    "        else:\n",
    "            out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)\n",
    "\n",
    "        out = channel_shuffle(out, 2)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ShuffleNetV2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        stages_repeats: List[int],\n",
    "        stages_out_channels: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        inverted_residual: Callable[..., nn.Module] = InvertedResidual,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if len(stages_repeats) != 3:\n",
    "            raise ValueError(\"expected stages_repeats as list of 3 positive ints\")\n",
    "        if len(stages_out_channels) != 5:\n",
    "            raise ValueError(\"expected stages_out_channels as list of 5 positive ints\")\n",
    "        self._stage_out_channels = stages_out_channels\n",
    "\n",
    "        input_channels = 1  # snorlax\n",
    "        output_channels = self._stage_out_channels[0]\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        input_channels = output_channels\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Static annotations for mypy\n",
    "        self.stage2: nn.Sequential\n",
    "        self.stage3: nn.Sequential\n",
    "        self.stage4: nn.Sequential\n",
    "        stage_names = [f\"stage{i}\" for i in [2, 3, 4]]\n",
    "        for name, repeats, output_channels in zip(stage_names, stages_repeats, self._stage_out_channels[1:]):\n",
    "            seq = [inverted_residual(input_channels, output_channels, 2)]\n",
    "            for i in range(repeats - 1):\n",
    "                seq.append(inverted_residual(output_channels, output_channels, 1))\n",
    "            setattr(self, name, nn.Sequential(*seq))\n",
    "            input_channels = output_channels\n",
    "\n",
    "        output_channels = self._stage_out_channels[-1]\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(output_channels, num_classes)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.mean([2, 3])  # globalpool\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _shufflenetv2(\n",
    "    weights,\n",
    "    progress: bool,\n",
    "    *args: Any,\n",
    "    **kwargs: Any,\n",
    ") -> ShuffleNetV2:\n",
    "\n",
    "    model = ShuffleNetV2(*args, **kwargs)\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights.get_state_dict(progress=progress))\n",
    "\n",
    "    return model\n",
    "\n",
    "def shufflenet_my(\n",
    "    *, weights = None, progress: bool = True, **kwargs: Any\n",
    ") -> ShuffleNetV2:\n",
    "    \"\"\"\n",
    "    Constructs a ShuffleNetV2 architecture with 0.5x output channels, as described in\n",
    "    `ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\n",
    "    <https://arxiv.org/abs/1807.11164>`__.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.ShuffleNet_V2_X0_5_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.ShuffleNet_V2_X0_5_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the\n",
    "            download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.shufflenetv2.ShuffleNetV2``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/shufflenetv2.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.ShuffleNet_V2_X0_5_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "\n",
    "    return _shufflenetv2(weights, progress, [4, 8, 4], [24, 48, 96, 192, 1024], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    net = shufflenet_my(num_classes=10, weights=None)\n",
    "    fc_features = net.fc.in_features\n",
    "    net.fc = nn.Linear(fc_features, 10)\n",
    "    return net\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "model = get_model().to(device)\n",
    "model.load_state_dict(torch.load('./models/shufflenet_2.pt',map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "threshold = -20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">canvas { border: 1px solid black; }</style><div id=\"board\"><canvas id=\"myCanvas\" width=\"100px\" height=\"100px\">Sorry, your browser doesn't support canvas technology.</canvas><p><button id=\"classify\" onclick=\"classify()\">Classify</button><button id=\"clear\" onclick=\"myClear()\">Clear</button>Result: <input type=\"text\" id=\"result_output\" size=\"5\" value=\"\"></p></div><script type=\"text/JavaScript\" src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js?ver=1.4.2\"></script><script type=\"text/javascript\">function init() {var myCanvas = document.getElementById(\"myCanvas\");var curColor = $('#selectColor option:selected').val();if(myCanvas){var isDown = false;var ctx = myCanvas.getContext(\"2d\");var canvasX, canvasY;ctx.lineWidth = 5;$(myCanvas).mousedown(function(e){isDown = true;ctx.beginPath();var parentOffset = $(this).parent().offset(); canvasX = e.pageX - parentOffset.left;canvasY = e.pageY - parentOffset.top;ctx.moveTo(canvasX, canvasY);}).mousemove(function(e){if(isDown != false) {var parentOffset = $(this).parent().offset(); canvasX = e.pageX - parentOffset.left;canvasY = e.pageY - parentOffset.top;ctx.lineTo(canvasX, canvasY);ctx.strokeStyle = curColor;ctx.stroke();}}).mouseup(function(e){isDown = false;ctx.closePath();});}$('#selectColor').change(function () {curColor = $('#selectColor option:selected').val();});}init();function handle_output(out) {document.getElementById(\"result_output\").value = out.content.data[\"text/plain\"];}function classify() {var kernel = IPython.notebook.kernel;var myCanvas = document.getElementById(\"myCanvas\");data = myCanvas.toDataURL('image/png');document.getElementById(\"result_output\").value = \"\";kernel.execute(\"classify('\" + data +\"')\",  { 'iopub' : {'output' : handle_output}}, {silent:false});}function myClear() {var myCanvas = document.getElementById(\"myCanvas\");myCanvas.getContext(\"2d\").clearRect(0, 0, myCanvas.width, myCanvas.height);}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hand drawing test\n",
    "from IPython.display import HTML\n",
    "from skimage.transform import resize\n",
    "import base64\n",
    "from imageio import imread\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "\n",
    "# def classify_ref(img):\n",
    "#     img = img[len('data:image/png;base64,'):].decode('base64')\n",
    "#     img = cv2.imdecode(np.fromstring(img, np.uint8), -1)\n",
    "#     img = cv2.resize(img[:,:,3], (28,28))\n",
    "#     img = img.astype(np.float32).reshape((1, 784))/255.0\n",
    "#     return model.predict(img)[0]\n",
    "\n",
    "def get_ood_score(out, T = 1.):\n",
    "    return -T * torch.logsumexp(out / T, dim=1).item()\n",
    "\n",
    "def predict(imgs):\n",
    "    x_transformed = torch.stack([transform(imgs[i]) for i in range(imgs.shape[0])])\n",
    "    \n",
    "    out = model(x_transformed)\n",
    "    preds = out.max(1)[1]\n",
    "\n",
    "    score = get_ood_score(preds)\n",
    "    preds[score > threshold] = 10\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def classify(img):\n",
    "    img = img[len('data:image/png;base64,'):]\n",
    "    img = base64.b64decode(img)\n",
    "    img = imread(img)    #img = rgb2gray(img)\n",
    "    img = resize(img[:,:,3], (28, 28))      #img = img/255.0\n",
    "    img = torch.from_numpy(img).float()\n",
    "    img = img.unsqueeze(0)\n",
    "    # out = model(img)\n",
    "    # pred = out.data.max(1)[1]\n",
    "\n",
    "    pred = model(img).cpu().numpy()[0]\n",
    "\n",
    "    return pred\n",
    "\n",
    "html = \"\"\"<style type=\"text/css\">canvas { border: 1px solid black; }</style><div id=\"board\"><canvas id=\"myCanvas\" width=\"100px\" height=\"100px\">Sorry, your browser doesn't support canvas technology.</canvas><p><button id=\"classify\" onclick=\"classify()\">Classify</button><button id=\"clear\" onclick=\"myClear()\">Clear</button>Result: <input type=\"text\" id=\"result_output\" size=\"5\" value=\"\"></p></div>\"\"\"\n",
    "script = \"\"\"<script type=\"text/JavaScript\" src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js?ver=1.4.2\"></script><script type=\"text/javascript\">function init() {var myCanvas = document.getElementById(\"myCanvas\");var curColor = $('#selectColor option:selected').val();if(myCanvas){var isDown = false;var ctx = myCanvas.getContext(\"2d\");var canvasX, canvasY;ctx.lineWidth = 5;$(myCanvas).mousedown(function(e){isDown = true;ctx.beginPath();var parentOffset = $(this).parent().offset(); canvasX = e.pageX - parentOffset.left;canvasY = e.pageY - parentOffset.top;ctx.moveTo(canvasX, canvasY);}).mousemove(function(e){if(isDown != false) {var parentOffset = $(this).parent().offset(); canvasX = e.pageX - parentOffset.left;canvasY = e.pageY - parentOffset.top;ctx.lineTo(canvasX, canvasY);ctx.strokeStyle = curColor;ctx.stroke();}}).mouseup(function(e){isDown = false;ctx.closePath();});}$('#selectColor').change(function () {curColor = $('#selectColor option:selected').val();});}init();function handle_output(out) {document.getElementById(\"result_output\").value = out.content.data[\"text/plain\"];}function classify() {var kernel = IPython.notebook.kernel;var myCanvas = document.getElementById(\"myCanvas\");data = myCanvas.toDataURL('image/png');document.getElementById(\"result_output\").value = \"\";kernel.execute(\"classify('\" + data +\"')\",  { 'iopub' : {'output' : handle_output}}, {silent:false});}function myClear() {var myCanvas = document.getElementById(\"myCanvas\");myCanvas.getContext(\"2d\").clearRect(0, 0, myCanvas.width, myCanvas.height);}</script>\"\"\"\n",
    "HTML(html+script)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
